---
layout: page
permalink: /Results/index.html
title: Corpus Results
---

<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>自适应图片</title>
<style>
  .center {
    text-align: center;
  }
  .responsive-img1 {
    max-width: 100%;
    height: auto;
  }
  .responsive-img2 {
  max-width: 65%;
  height: auto;
  }
</style>
</head>
<body>
<div class="center">
</div>
</body>
</html>

We tested text-dependent and text-independent speaker verification to compare metrics under the same and different phonetic contexts, respectively. For enrollment, we used three different utterances of the same pass-phrase from the same speaker, with one segment as the test utterance. Each trial consists of enrollment and test. The number of trials, shown in Table IV, includes roughly ten times more imposter trials than target trials, similar to the RSR2015 dataset. Results are shown in Table V. 

<center>
<img src="https://slash1028.github.io/Image/performence.png" class="responsive-img1" alt="自适应图片">
</center>
<br>

Lower equal error rate (EER) and minimum decision cost function (minDCF) indicate better performance. Since Sub3Vox is derived from VoxCeleb1 and the model is pre-trained on VoxCeleb2, it simulates real-life scenarios with unseen speakers and passwords. Testing on future Sub3Vox versions derived from VoxCeleb2 should yield better performance with lower EER and minDCF.
